{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tutorial**:\n",
    " \n",
    "1. Download project and install dependencies\n",
    "2. Preprocess data\n",
    "3. Segment preprocessed data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Download project and install dependencies**\n",
    "\n",
    "Download the github project with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/HelmholtzAI-Consultants-Munich/AURORA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install all requirements listed in requirements.txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd AURORA\n",
    "!pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "os.makedirs(\"Examples\", exist_ok=\"T\")\n",
    "\n",
    "url_label = \"https://files-accl.zohopublic.eu/public/workdrive-public/download/bbd0p91ca3309beac4eb69f78a103d686d53a?x-cli-msg=%7B%22isFileOwner%22%3Afalse%2C%22bbd0p91ca3309beac4eb69f78a103d686d53a%22%3A%224uQNLsigiFF-lVsGRB%22%2C%22version%22%3A%221.0%22%2C%224uQNLsigiFF-lVsGRB_user_uuid%22%3A%22%242442093196452756052%22%7D\"\n",
    "\n",
    "myfile = requests.get(url_label)\n",
    "open(\"Examples/Nifti.zip\", 'wb').write(myfile.content)\n",
    "\n",
    "!unzip Examples/Nifti.zip -d Examples/Nifti"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Preprocess data**\n",
    "\n",
    "The provided models need coregistered, skullstripped sequences as input.\n",
    "\n",
    "We recommend BraTS-Toolkit (https://github.com/neuronflow/BraTS-Toolkit) for preprocessing, which covers the entire image analysis workflow prior to tumor segmentation.\n",
    "\n",
    "BraTS-Toolkit can be downloaded with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install BraTS-Toolkit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please follow the instructione on the Github-page for installation and setup advice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Segment preprocessed data**\n",
    "\n",
    "We provide sample data from the ASNR-MICCAI BraTS Brain Metastasis Challenge, which is already preprocessed.\n",
    "\n",
    "Minimal mode: Segmentation without test-time augmentation with only T1-CE as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1: False t1c: True t2: False flair: False\n",
      "mode: t1c-o\n",
      "BasicUNet features: (32, 32, 64, 128, 256, 32).\n",
      "start: 2023-06-10_18-12-37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape: torch.Size([1, 1, 240, 240, 155])\n",
      "outputs: torch.Size([1, 2, 240, 240, 155])\n",
      "data length: 3\n",
      "outputs shape 0: 1\n",
      "end: 2023-06-10_18-12-39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lib import single_inference\n",
    "\n",
    "single_inference(\n",
    "    t1c_file=\"Examples/BraTS-MET-00110-000-t1c.nii.gz\",\n",
    "    segmentation_file=\"your_segmentation_file.nii.gz\",\n",
    "    tta=False,  # optional: whether to use test time augmentations\n",
    "    verbosity=True,  # optional: verbosity of the output\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many possibilities for customization:\n",
    "- Any of the following combination of sequences can be supplied: \n",
    "    - T1-CE + T1 + T2 + T2-FLAIR\n",
    "    - T1-CE only\n",
    "    - T1 only\n",
    "    - T2-FLAIR only\n",
    "    - T1-CE + T2-FLAIR\n",
    "    - T1-CE + T1\n",
    "    - T1-CE + T1 + T2-FLAIR\n",
    "- Instead of only saving the final output consiting of one file with 2 labels, additional fiules with labels for the whole lesion (metastasis + edema) or the metastasis only can also be saved.\n",
    "- Test-time augmentation can be enabled. Segmentation with TTA will take 12 times longer than without TTA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1: True t1c: True t2: True flair: True\n",
      "mode: t1-t1c-t2-fla\n",
      "BasicUNet features: (32, 32, 64, 128, 256, 32).\n",
      "start: 2023-06-10_18-24-44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:18<00:00, 18.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n",
      "inputs shape: torch.Size([1, 4, 240, 240, 155])\n",
      "outputs: torch.Size([1, 2, 240, 240, 155])\n",
      "data length: 6\n",
      "outputs shape 0: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:18<00:00, 18.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end: 2023-06-10_18-25-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lib import single_inference\n",
    "\n",
    "single_inference(\n",
    "    t1_file=\"Examples/BraTS-MET-00110-000-t1n.nii.gz\",\n",
    "    t1c_file=\"Examples/BraTS-MET-00110-000-t1c.nii.gz\",\n",
    "    t2_file=\"Examples/BraTS-MET-00110-000-t2w.nii.gz\",\n",
    "    fla_file=\"Examples/BraTS-MET-00110-000-t2f.nii.gz\",\n",
    "    segmentation_file=\"your_segmentation_file.nii.gz\",\n",
    "    whole_network_outputs_file=\"your_whole_lesion_file.nii.gz\",  # optional: whether to save network outputs for the whole lesion (metastasis + edema)\n",
    "    metastasis_network_outputs_file=\"your_metastasis_file.nii.gz\",  # optional: whether to save network outputs for the metastasis\n",
    "    cuda_devices=\"0\",  # optional: which CUDA devices to use\n",
    "    tta=True,  # optional: whether to use test time augmentations\n",
    "    sliding_window_batch_size=1,  # optional: adjust to fit your GPU memory, each step requires an additional 2 GB of VRAM, increasing is not recommended for single interference\n",
    "    workers=8,  # optional: workers for the data laoder\n",
    "    threshold=0.5,  # optional: where to threshold the network outputs\n",
    "    sliding_window_overlap=0.5,  # optional: overlap for the sliding window\n",
    "    model_selection=\"best\",  # optional: choose best or last checkpoint, best is recommended\n",
    "    verbosity=True,  # optional: verbosity of the output\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
